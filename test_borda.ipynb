{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Borda Count Voting Analysis\n",
        "\n",
        "This notebook analyzes strategic manipulation in Borda count voting. It computes the winner under truthful voting and finds the best strategic deviation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Configuration loaded\n",
            "  True preference: C > A > B\n",
            "  Manipulator controls: 20 votes\n",
            "  Other voters: 80 votes\n"
          ]
        }
      ],
      "source": [
        "# Configuration and Constants\n",
        "\n",
        "# Borda scoring: 1st place = 2 points, 2nd place = 1 point, 3rd place = 0 points\n",
        "BORDA_SCORES = {0: 2, 1: 1, 2: 0}\n",
        "\n",
        "# Voting profile (excluding the manipulator's 15 votes)\n",
        "OTHER_VOTERS = {\n",
        "    ('A', 'B', 'C'): 15,\n",
        "    ('A', 'C', 'B'): 25,\n",
        "    ('B', 'A', 'C'): 10,\n",
        "    ('B', 'C', 'A'): 15,\n",
        "    ('C', 'B', 'A'): 15,\n",
        "}\n",
        "\n",
        "# True preference of the manipulator\n",
        "TRUE_PREFERENCE = ('C', 'A', 'B')\n",
        "MANIPULATOR_VOTES = 20\n",
        "\n",
        "# Utility mapping based on true preference C > A > B\n",
        "UTILITY = {'C': 2, 'A': 1, 'B': 0}\n",
        "\n",
        "print(\"✓ Configuration loaded\")\n",
        "print(f\"  True preference: {' > '.join(TRUE_PREFERENCE)}\")\n",
        "print(f\"  Manipulator controls: {MANIPULATOR_VOTES} votes\")\n",
        "print(f\"  Other voters: {sum(OTHER_VOTERS.values())} votes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Helper functions defined\n"
          ]
        }
      ],
      "source": [
        "def compute_borda_scores(voter_profile):\n",
        "    \"\"\"\n",
        "    Compute Borda scores for each candidate given a voter profile.\n",
        "    \n",
        "    Args:\n",
        "        voter_profile: Dictionary mapping rankings (tuples) to number of voters\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary mapping candidates to their total Borda scores\n",
        "    \"\"\"\n",
        "    scores = {'A': 0, 'B': 0, 'C': 0}\n",
        "    \n",
        "    for ranking, count in voter_profile.items():\n",
        "        for position, candidate in enumerate(ranking):\n",
        "            scores[candidate] += count * BORDA_SCORES[position]\n",
        "    \n",
        "    return scores\n",
        "\n",
        "\n",
        "def determine_winner(scores):\n",
        "    \"\"\"\n",
        "    Determine the winner based on Borda scores.\n",
        "    In case of a tie, returns the candidate with lexicographically first name.\n",
        "    \n",
        "    Args:\n",
        "        scores: Dictionary mapping candidates to their Borda scores\n",
        "        \n",
        "    Returns:\n",
        "        The winning candidate\n",
        "    \"\"\"\n",
        "    max_score = max(scores.values())\n",
        "    winners = [cand for cand, score in scores.items() if score == max_score]\n",
        "    return sorted(winners)[0]  # Lexicographic tie-breaking\n",
        "\n",
        "\n",
        "def compute_outcome(manipulator_ranking):\n",
        "    \"\"\"\n",
        "    Compute the election outcome given the manipulator's ranking.\n",
        "    \n",
        "    Args:\n",
        "        manipulator_ranking: Tuple representing the manipulator's ranking (e.g., ('C', 'A', 'B'))\n",
        "        \n",
        "    Returns:\n",
        "        Tuple of (winner, scores_dict)\n",
        "    \"\"\"\n",
        "    # Create full profile including manipulator\n",
        "    full_profile = OTHER_VOTERS.copy()\n",
        "    full_profile[manipulator_ranking] = full_profile.get(manipulator_ranking, 0) + MANIPULATOR_VOTES\n",
        "    \n",
        "    scores = compute_borda_scores(full_profile)\n",
        "    winner = determine_winner(scores)\n",
        "    \n",
        "    return winner, scores\n",
        "\n",
        "\n",
        "def get_all_rankings():\n",
        "    \"\"\"\n",
        "    Generate all possible rankings of three candidates.\n",
        "    \n",
        "    Returns:\n",
        "        List of tuples representing all 6 possible rankings\n",
        "    \"\"\"\n",
        "    from itertools import permutations\n",
        "    candidates = ['A', 'B', 'C']\n",
        "    return list(permutations(candidates))\n",
        "\n",
        "print(\"✓ Helper functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Truthful Voting Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "TRUTHFUL VOTING\n",
            "================================================================================\n",
            "Ranking: C > A > B\n",
            "\n",
            "Borda scores:\n",
            "  A: 110 points\n",
            "  C: 110 points\n",
            "  B: 80 points\n",
            "\n",
            "Winner: A\n",
            "Utility (based on C > A > B): 1\n",
            "  (C=2, A=1, B=0)\n"
          ]
        }
      ],
      "source": [
        "# Compute truthful outcome\n",
        "truthful_winner, truthful_scores = compute_outcome(TRUE_PREFERENCE)\n",
        "truthful_utility = UTILITY[truthful_winner]\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"TRUTHFUL VOTING\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Ranking: {' > '.join(TRUE_PREFERENCE)}\")\n",
        "print(f\"\\nBorda scores:\")\n",
        "for candidate, score in sorted(truthful_scores.items(), key=lambda x: -x[1]):\n",
        "    print(f\"  {candidate}: {score} points\")\n",
        "print(f\"\\nWinner: {truthful_winner}\")\n",
        "print(f\"Utility (based on C > A > B): {truthful_utility}\")\n",
        "print(f\"  (C=2, A=1, B=0)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing All Possible Deviations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "TESTING ALL POSSIBLE RANKINGS\n",
            "================================================================================\n",
            "\n",
            "Ranking: A > B > C\n",
            "  Scores: A=130, B=100, C=70\n",
            "  Winner: A (utility: 1)\n",
            "\n",
            "Ranking: A > C > B\n",
            "  Scores: A=130, B=80, C=90\n",
            "  Winner: A (utility: 1)\n",
            "\n",
            "Ranking: B > A > C\n",
            "  Scores: A=110, B=120, C=70\n",
            "  Winner: B (utility: 0)\n",
            "\n",
            "Ranking: B > C > A\n",
            "  Scores: A=90, B=120, C=90\n",
            "  Winner: B (utility: 0)\n",
            "\n",
            "Ranking: C > A > B [TRUTHFUL]\n",
            "  Scores: A=110, B=80, C=110\n",
            "  Winner: A (utility: 1)\n",
            "\n",
            "Ranking: C > B > A\n",
            "  Scores: A=90, B=100, C=110\n",
            "  Winner: C (utility: 2)\n"
          ]
        }
      ],
      "source": [
        "# Test all possible rankings\n",
        "all_rankings = get_all_rankings()\n",
        "all_results = []\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"TESTING ALL POSSIBLE RANKINGS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for ranking in all_rankings:\n",
        "    winner, scores = compute_outcome(ranking)\n",
        "    utility = UTILITY[winner]\n",
        "    \n",
        "    result = {\n",
        "        'ranking': ranking,\n",
        "        'winner': winner,\n",
        "        'scores': scores,\n",
        "        'utility': utility\n",
        "    }\n",
        "    all_results.append(result)\n",
        "    \n",
        "    ranking_str = ' > '.join(ranking)\n",
        "    is_truthful = ranking == TRUE_PREFERENCE\n",
        "    marker = \" [TRUTHFUL]\" if is_truthful else \"\"\n",
        "    \n",
        "    print(f\"\\nRanking: {ranking_str}{marker}\")\n",
        "    print(f\"  Scores: A={scores['A']}, B={scores['B']}, C={scores['C']}\")\n",
        "    print(f\"  Winner: {winner} (utility: {utility})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finding Best Strategic Deviation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FINDING BEST STRATEGIC DEVIATION\n",
            "================================================================================\n",
            "\n",
            "Truthful outcome:\n",
            "  Ranking: C > A > B\n",
            "  Winner: A (utility: 1)\n",
            "\n",
            "Best deviation:\n",
            "  Ranking: C > B > A\n",
            "  Winner: C (utility: 2)\n",
            "  Scores: {'A': 90, 'B': 100, 'C': 110}\n",
            "\n",
            "✓ Strategic manipulation improves outcome by 1 utility!\n",
            "  Can change winner from A to C\n"
          ]
        }
      ],
      "source": [
        "# Find best deviation (excluding truthful ranking)\n",
        "deviations = [r for r in all_results if r['ranking'] != TRUE_PREFERENCE]\n",
        "best_deviation = max(deviations, key=lambda x: x['utility'])\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"FINDING BEST STRATEGIC DEVIATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nTruthful outcome:\")\n",
        "print(f\"  Ranking: {' > '.join(TRUE_PREFERENCE)}\")\n",
        "print(f\"  Winner: {truthful_winner} (utility: {truthful_utility})\")\n",
        "\n",
        "print(f\"\\nBest deviation:\")\n",
        "print(f\"  Ranking: {' > '.join(best_deviation['ranking'])}\")\n",
        "print(f\"  Winner: {best_deviation['winner']} (utility: {best_deviation['utility']})\")\n",
        "print(f\"  Scores: {best_deviation['scores']}\")\n",
        "\n",
        "if best_deviation['utility'] > truthful_utility:\n",
        "    improvement = best_deviation['utility'] - truthful_utility\n",
        "    print(f\"\\n✓ Strategic manipulation improves outcome by {improvement} utility!\")\n",
        "    print(f\"  Can change winner from {truthful_winner} to {best_deviation['winner']}\")\n",
        "else:\n",
        "    print(f\"\\n✗ No beneficial deviation found.\")\n",
        "    print(f\"  Truthful voting is already optimal.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detailed Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ALL RANKINGS SORTED BY UTILITY\n",
            "================================================================================\n",
            "1. C > B > A\n",
            "   Winner: C, Utility: 2\n",
            "2. A > B > C\n",
            "   Winner: A, Utility: 1\n",
            "3. A > C > B\n",
            "   Winner: A, Utility: 1\n",
            "4. C > A > B [TRUTHFUL]\n",
            "   Winner: A, Utility: 1\n",
            "5. B > A > C\n",
            "   Winner: B, Utility: 0\n",
            "6. B > C > A\n",
            "   Winner: B, Utility: 0\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"ALL RANKINGS SORTED BY UTILITY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "sorted_results = sorted(all_results, key=lambda x: -x['utility'])\n",
        "for i, result in enumerate(sorted_results, 1):\n",
        "    ranking_str = ' > '.join(result['ranking'])\n",
        "    is_truthful = result['ranking'] == TRUE_PREFERENCE\n",
        "    marker = \" [TRUTHFUL]\" if is_truthful else \"\"\n",
        "    print(f\"{i}. {ranking_str}{marker}\")\n",
        "    print(f\"   Winner: {result['winner']}, Utility: {result['utility']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Exploration Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Interactive functions defined\n",
            "\n",
            "You can now use:\n",
            "  - explore_ranking(('A', 'C', 'B'))\n",
            "  - compare_rankings(TRUE_PREFERENCE, ('A', 'C', 'B'))\n",
            "  - all_results  # List of all ranking results\n",
            "  - best_deviation  # Best strategic deviation\n"
          ]
        }
      ],
      "source": [
        "def explore_ranking(ranking_tuple):\n",
        "    \"\"\"\n",
        "    Explore a specific ranking interactively.\n",
        "    \n",
        "    Usage:\n",
        "        explore_ranking(('A', 'C', 'B'))\n",
        "    \"\"\"\n",
        "    winner, scores = compute_outcome(ranking_tuple)\n",
        "    utility = UTILITY[winner]\n",
        "    \n",
        "    print(f\"\\nExploring ranking: {' > '.join(ranking_tuple)}\")\n",
        "    print(f\"  Scores: {scores}\")\n",
        "    print(f\"  Winner: {winner}\")\n",
        "    print(f\"  Utility: {utility}\")\n",
        "    \n",
        "    if ranking_tuple == TRUE_PREFERENCE:\n",
        "        print(f\"  [This is the truthful ranking]\")\n",
        "    else:\n",
        "        diff = utility - truthful_utility\n",
        "        if diff > 0:\n",
        "            print(f\"  [Better than truthful by {diff} utility]\")\n",
        "        elif diff < 0:\n",
        "            print(f\"  [Worse than truthful by {abs(diff)} utility]\")\n",
        "        else:\n",
        "            print(f\"  [Same utility as truthful]\")\n",
        "    \n",
        "    return winner, scores, utility\n",
        "\n",
        "\n",
        "def compare_rankings(ranking1, ranking2):\n",
        "    \"\"\"\n",
        "    Compare two rankings side by side.\n",
        "    \n",
        "    Usage:\n",
        "        compare_rankings(TRUE_PREFERENCE, ('A', 'C', 'B'))\n",
        "    \"\"\"\n",
        "    r1_winner, r1_scores, r1_util = explore_ranking(ranking1)\n",
        "    r2_winner, r2_scores, r2_util = explore_ranking(ranking2)\n",
        "    \n",
        "    print(f\"\\nComparison:\")\n",
        "    print(f\"  Ranking 1 ({' > '.join(ranking1)}): {r1_winner} wins, utility {r1_util}\")\n",
        "    print(f\"  Ranking 2 ({' > '.join(ranking2)}): {r2_winner} wins, utility {r2_util}\")\n",
        "    \n",
        "    if r2_util > r1_util:\n",
        "        print(f\"  → Ranking 2 is better by {r2_util - r1_util} utility\")\n",
        "    elif r1_util > r2_util:\n",
        "        print(f\"  → Ranking 1 is better by {r1_util - r2_util} utility\")\n",
        "    else:\n",
        "        print(f\"  → Both rankings yield the same utility\")\n",
        "\n",
        "print(\"✓ Interactive functions defined\")\n",
        "print(\"\\nYou can now use:\")\n",
        "print(\"  - explore_ranking(('A', 'C', 'B'))\")\n",
        "print(\"  - compare_rankings(TRUE_PREFERENCE, ('A', 'C', 'B'))\")\n",
        "print(\"  - all_results  # List of all ranking results\")\n",
        "print(\"  - best_deviation  # Best strategic deviation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example: Explore Best Deviation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Exploring ranking: C > A > B\n",
            "  Scores: {'A': 110, 'B': 80, 'C': 110}\n",
            "  Winner: A\n",
            "  Utility: 1\n",
            "  [This is the truthful ranking]\n",
            "\n",
            "Exploring ranking: C > B > A\n",
            "  Scores: {'A': 90, 'B': 100, 'C': 110}\n",
            "  Winner: C\n",
            "  Utility: 2\n",
            "  [Better than truthful by 1 utility]\n",
            "\n",
            "Comparison:\n",
            "  Ranking 1 (C > A > B): A wins, utility 1\n",
            "  Ranking 2 (C > B > A): C wins, utility 2\n",
            "  → Ranking 2 is better by 1 utility\n"
          ]
        }
      ],
      "source": [
        "# Compare truthful vs best deviation\n",
        "if best_deviation['utility'] > truthful_utility:\n",
        "    compare_rankings(TRUE_PREFERENCE, best_deviation['ranking'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
